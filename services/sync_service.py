from datetime import datetime, date
from calendar import monthrange
from concurrent.futures import ThreadPoolExecutor, as_completed

from logging_config import logger
from database.models.sync_state import SyncState

from services.tally_connector import TallyConnector
from services.data_processor import (
    parse_inventory_voucher,
    parse_ledger_voucher,
    parse_ledgers,
    parse_trial_balance,
)
from database.database_processor import (
    get_sync_state,
    update_sync_state,
    upsert_ledgers,
    upsert_and_advance_month,
    upsert_sales_vouchers,
    upsert_purchase_vouchers,
    upsert_credit_notes,
    upsert_debit_notes,
    upsert_receipt_vouchers,
    upsert_payment_vouchers,
    upsert_journal_vouchers,
    upsert_contra_vouchers,
    upsert_trial_balance,
    INVENTORY_MODEL_MAP,
    LEDGER_MODEL_MAP,
    _upsert_inventory_voucher_in_session,
    _upsert_ledger_voucher_in_session,
    _get_session,
)

SNAPSHOT_CHUNK_MONTHS = 3

VOUCHER_WORKERS = 2

VOUCHER_CONFIG = [
    {
        'voucher_type'    : 'sales',
        'snapshot_fetch'  : 'fetch_sales',
        'cdc_fetch'       : 'fetch_sales_cdc',
        'parser'          : parse_inventory_voucher,
        'upsert'          : upsert_sales_vouchers,
        'parser_type_name': 'Sales Vouchers',
        'kind'            : 'inventory',
    },
    {
        'voucher_type'    : 'purchase',
        'snapshot_fetch'  : 'fetch_purchase',
        'cdc_fetch'       : 'fetch_purchase_cdc',
        'parser'          : parse_inventory_voucher,
        'upsert'          : upsert_purchase_vouchers,
        'parser_type_name': 'Purchase Vouchers',
        'kind'            : 'inventory',
    },
    {
        'voucher_type'    : 'credit_note',
        'snapshot_fetch'  : 'fetch_credit_note',
        'cdc_fetch'       : 'fetch_credit_note_cdc',
        'parser'          : parse_inventory_voucher,
        'upsert'          : upsert_credit_notes,
        'parser_type_name': 'Credit Note',
        'kind'            : 'inventory',
    },
    {
        'voucher_type'    : 'debit_note',
        'snapshot_fetch'  : 'fetch_debit_note',
        'cdc_fetch'       : 'fetch_debit_note_cdc',
        'parser'          : parse_inventory_voucher,
        'upsert'          : upsert_debit_notes,
        'parser_type_name': 'Debit Note',
        'kind'            : 'inventory',
    },
    {
        'voucher_type'    : 'receipt',
        'snapshot_fetch'  : 'fetch_receipt',
        'cdc_fetch'       : 'fetch_receipt_cdc',
        'parser'          : parse_ledger_voucher,
        'upsert'          : upsert_receipt_vouchers,
        'parser_type_name': 'Receipt Vouchers',
        'kind'            : 'ledger',
    },
    {
        'voucher_type'    : 'payment',
        'snapshot_fetch'  : 'fetch_payment',
        'cdc_fetch'       : 'fetch_payment_cdc',
        'parser'          : parse_ledger_voucher,
        'upsert'          : upsert_payment_vouchers,
        'parser_type_name': 'Payment Vouchers',
        'kind'            : 'ledger',
    },
    {
        'voucher_type'    : 'journal',
        'snapshot_fetch'  : 'fetch_journal',
        'cdc_fetch'       : 'fetch_journal_cdc',
        'parser'          : parse_ledger_voucher,
        'upsert'          : upsert_journal_vouchers,
        'parser_type_name': 'Journal Vouchers',
        'kind'            : 'ledger',
    },
    {
        'voucher_type'    : 'contra',
        'snapshot_fetch'  : 'fetch_contra',
        'cdc_fetch'       : 'fetch_contra_cdc',
        'parser'          : parse_ledger_voucher,
        'upsert'          : upsert_contra_vouchers,
        'parser_type_name': 'Contra Vouchers',
        'kind'            : 'ledger',
    },
]

def _get_max_alter_id(rows: list) -> int:
    if not rows:
        return 0
    return max(int(r.get('alter_id', 0)) for r in rows)

def _resolve_from_date(company: dict) -> str:
    starting_from = company.get('starting_from', '')
    if starting_from:
        cleaned = str(starting_from).strip().replace('-', '')
        if len(cleaned) == 8 and cleaned.isdigit():
            return cleaned
    fallback = '20240401'
    logger.warning(f"No valid starting_from for '{company.get('name')}' — using fallback {fallback}")
    return fallback

def _generate_chunks(from_date_str: str, to_date_str: str, chunk_months: int = SNAPSHOT_CHUNK_MONTHS):
    start = datetime.strptime(from_date_str, '%Y%m%d').date()
    end   = datetime.strptime(to_date_str,   '%Y%m%d').date()
    chunk_start = start

    while chunk_start <= end:

        end_month = chunk_start.month + chunk_months - 1
        end_year  = chunk_start.year + (end_month - 1) // 12
        end_month = (end_month - 1) % 12 + 1
        last_day  = monthrange(end_year, end_month)[1]

        chunk_end  = min(date(end_year, end_month, last_day), end)
        month_str  = chunk_end.strftime('%Y%m')
        chunk_from = chunk_start.strftime('%Y%m%d')
        chunk_to   = chunk_end.strftime('%Y%m%d')

        yield chunk_from, chunk_to, month_str

        if chunk_end >= end:
            break

        next_month  = chunk_end.month + 1 if chunk_end.month < 12 else 1
        next_year   = chunk_end.year      if chunk_end.month < 12 else chunk_end.year + 1
        chunk_start = date(next_year, next_month, 1)

def _mark_chunk_done(company_name: str, voucher_type: str, month_str: str, engine):
    db = _get_session(engine)
    try:
        state = db.query(SyncState).filter_by(
            company_name=company_name,
            voucher_type=voucher_type,
        ).first()

        if state:
            state.last_synced_month = month_str
            state.last_sync_time    = datetime.utcnow()
        else:
            db.add(SyncState(
                company_name      = company_name,
                voucher_type      = voucher_type,
                last_alter_id     = 0,
                is_initial_done   = False,
                last_synced_month = month_str,
                last_sync_time    = datetime.utcnow(),
            ))

        db.commit()
    except Exception:
        db.rollback()
        logger.exception(f"[{company_name}][{voucher_type}] Failed to mark chunk {month_str} done")
        raise
    finally:
        db.close()

def _sync_trial_balance(company_name: str, tally: TallyConnector, engine, from_date: str, to_date: str):
    logger.info(f"[{company_name}] Syncing Trial Balance | {from_date} -> {to_date}")
    try:

        state              = get_sync_state(company_name, 'trial_balance', engine)
        saved_alter_id     = state.last_alter_id if state else 0

        xml = tally.fetch_trial_balance(company_name=company_name, from_date=from_date, to_date=to_date)
        if not xml:
            logger.warning(f"[{company_name}] No trial balance data from Tally")
            return

        rows = parse_trial_balance(xml, company_name, from_date, to_date)
        if not rows:
            logger.warning(f"[{company_name}] Trial balance parsed 0 rows")
            return

        max_alter_id = _get_max_alter_id(rows)

        if max_alter_id == saved_alter_id and saved_alter_id > 0:
            logger.info(
                f"[{company_name}] Trial Balance SKIPPED upsert — "
                f"max_alter_id unchanged ({max_alter_id}), no changes in Tally"
            )
            return

        upsert_trial_balance(rows, engine)
        update_sync_state(company_name, 'trial_balance', max_alter_id, engine)
        logger.info(
            f"[{company_name}] Trial Balance done | "
            f"rows={len(rows)} | max_alter_id={max_alter_id} "
            f"(was {saved_alter_id})"
        )

    except Exception:
        logger.exception(f"[{company_name}] Trial Balance sync failed")

def _sync_ledgers(company_name: str, tally: TallyConnector, engine):
    logger.info(f"[{company_name}] Syncing Ledgers")
    try:
        state           = get_sync_state(company_name, 'ledger', engine)
        is_initial_done = state.is_initial_done if state else False
        last_alter_id   = state.last_alter_id   if state else 0

        if is_initial_done:
            logger.info(f"[{company_name}][ledger] CDC | last_alter_id={last_alter_id}")
            xml = tally.fetch_ledger_cdc(company_name=company_name, last_alter_id=last_alter_id)

            if not xml:
                logger.info(f"[{company_name}][ledger] CDC: no new/changed ledgers")
                return

            rows = parse_ledgers(xml, company_name)
            if not rows:
                logger.info(f"[{company_name}][ledger] CDC: 0 rows (nothing changed since AlterID {last_alter_id})")
                return

            upsert_ledgers(rows, engine)
            new_max = _get_max_alter_id(rows)
            update_sync_state(company_name, 'ledger', new_max, engine, is_initial_done=True)
            logger.info(f"[{company_name}][ledger] CDC done | rows={len(rows)} | new max_alter_id={new_max}")
            return

        logger.info(f"[{company_name}][ledger] SNAPSHOT - fetching all ledgers for the first time")
        xml = tally.fetch_ledgers(company_name=company_name)

        if not xml:
            logger.warning(f"[{company_name}][ledger] No ledger data from Tally")
            return

        rows = parse_ledgers(xml, company_name)
        if not rows:
            logger.warning(f"[{company_name}][ledger] Snapshot parsed 0 rows")
            return

        upsert_ledgers(rows, engine)
        max_alter_id = _get_max_alter_id(rows)
        update_sync_state(company_name, 'ledger', max_alter_id, engine, is_initial_done=True)
        logger.info(
            f"[{company_name}][ledger] Snapshot done | "
            f"rows={len(rows)} | max_alter_id={max_alter_id} | CDC enabled from next run"
        )

    except Exception:
        logger.exception(f"[{company_name}] Ledger sync failed")

def _sync_voucher(
    company_name: str,
    config:       dict,
    tally:        TallyConnector,
    engine,
    from_date:    str,
    to_date:      str,
):
    voucher_type     = config['voucher_type']
    snapshot_fetch   = config['snapshot_fetch']
    cdc_fetch        = config['cdc_fetch']
    parser           = config['parser']
    upsert           = config['upsert']
    parser_type_name = config['parser_type_name']
    kind             = config['kind']

    logger.info(f"[{company_name}][{voucher_type}] Starting")

    try:

        state             = get_sync_state(company_name, voucher_type, engine)
        is_initial_done   = state.is_initial_done   if state else False
        last_alter_id     = state.last_alter_id     if state else 0
        last_synced_month = state.last_synced_month if state else None

        if is_initial_done:
            logger.info(f"[{company_name}][{voucher_type}] CDC | last_alter_id={last_alter_id}")

            t0 = datetime.now()

            fetch_fn = getattr(tally, cdc_fetch)
            xml      = fetch_fn(company_name=company_name, last_alter_id=last_alter_id)

            fetch_ms = int((datetime.now() - t0).total_seconds() * 1000)

            if not xml:
                logger.warning(f"[{company_name}][{voucher_type}] CDC: no response from Tally ({fetch_ms}ms)")
                return

            rows = parser(xml, company_name, parser_type_name)

            if not rows:

                logger.info(
                    f"[{company_name}][{voucher_type}] CDC: nothing changed "
                    f"(fetch={fetch_ms}ms, 0 rows)"
                )
                return

            t1 = datetime.now()
            upsert(rows, engine)
            upsert_ms = int((datetime.now() - t1).total_seconds() * 1000)

            new_max = _get_max_alter_id(rows)
            update_sync_state(company_name, voucher_type, new_max, engine, is_initial_done=True)
            logger.info(
                f"[{company_name}][{voucher_type}] CDC done | "
                f"rows={len(rows)} | new max_alter_id={new_max} | "
                f"fetch={fetch_ms}ms upsert={upsert_ms}ms"
            )
            return

        logger.info(
            f"[{company_name}][{voucher_type}] SNAPSHOT "
            f"({SNAPSHOT_CHUNK_MONTHS}-month chunks) | {from_date} → {to_date}"
        )

        if kind == 'inventory':
            model_class = INVENTORY_MODEL_MAP[voucher_type]
            upsert_fn   = _upsert_inventory_voucher_in_session
        else:
            model_class = LEDGER_MODEL_MAP[voucher_type]
            upsert_fn   = _upsert_ledger_voucher_in_session

        fetch_fn      = getattr(tally, snapshot_fetch)
        total_rows    = 0
        chunks_done   = 0

        all_alter_ids = [last_alter_id] if last_alter_id > 0 else []

        for chunk_from, chunk_to, month_str in _generate_chunks(from_date, to_date):

            if last_synced_month and month_str <= last_synced_month:
                logger.debug(f"[{company_name}][{voucher_type}] Skipping already-done chunk {month_str}")
                continue

            logger.info(f"[{company_name}][{voucher_type}] Chunk {month_str} | {chunk_from} → {chunk_to}")

            xml = fetch_fn(company_name=company_name, from_date=chunk_from, to_date=chunk_to)

            if not xml:

                logger.info(f"[{company_name}][{voucher_type}] Chunk {month_str}: empty response, advancing")
                _mark_chunk_done(company_name, voucher_type, month_str, engine)
                chunks_done += 1
                continue

            rows = parser(xml, company_name, parser_type_name)

            if not rows:
                logger.info(f"[{company_name}][{voucher_type}] Chunk {month_str}: 0 rows parsed, advancing")
                _mark_chunk_done(company_name, voucher_type, month_str, engine)
                chunks_done += 1
                continue

            chunk_max = max((int(r.get('alter_id', 0)) for r in rows), default=0)
            upsert_and_advance_month(
                rows                = rows,
                model_class         = model_class,
                upsert_fn           = upsert_fn,
                company_name        = company_name,
                voucher_type        = voucher_type,
                month_str           = month_str,
                engine              = engine,
                chunk_max_alter_id  = chunk_max,
            )

            all_alter_ids.extend(int(r.get('alter_id', 0)) for r in rows)
            total_rows  += len(rows)
            chunks_done += 1

        final_alter_id = max(all_alter_ids) if all_alter_ids else 0
        update_sync_state(
            company_name      = company_name,
            voucher_type      = voucher_type,
            last_alter_id     = final_alter_id,
            engine            = engine,
            last_synced_month = to_date[:6],
            is_initial_done   = True,
        )

        logger.info(
            f"[{company_name}][{voucher_type}] Snapshot complete | "
            f"chunks={chunks_done} | total_rows={total_rows} | max_alter_id={final_alter_id}"
        )

    except Exception:
        logger.exception(
            f"[{company_name}][{voucher_type}] Sync failed — "
            f"will resume from last committed chunk on next run"
        )

def sync_company(
    company:          dict,
    tally:            TallyConnector,
    engine,
    to_date:          str,
    manual_from_date: str = None,
):
    comp_name = company.get('name', '').strip()
    from_date = manual_from_date if manual_from_date else _resolve_from_date(company)

    logger.info('=' * 60)
    logger.info(f'Syncing company  : {comp_name}')
    logger.info(f'Date range       : {from_date} → {to_date}')
    logger.info(f'Chunk size       : {SNAPSHOT_CHUNK_MONTHS} months per API call')
    logger.info(f'Parallel workers : {VOUCHER_WORKERS} threads')
    logger.info('=' * 60)

    start_time = datetime.now()

    _sync_ledgers(comp_name, tally, engine)
    _sync_trial_balance(comp_name, tally, engine, from_date, to_date)

    logger.info(f"[{comp_name}] Launching {len(VOUCHER_CONFIG)} voucher syncs …")
    with ThreadPoolExecutor(max_workers=VOUCHER_WORKERS) as executor:
        futures = {
            executor.submit(
                _sync_voucher,
                company_name = comp_name,
                config       = config,
                tally        = tally,
                engine       = engine,
                from_date    = from_date,
                to_date      = to_date,
            ): config['voucher_type']
            for config in VOUCHER_CONFIG
        }

        for future in as_completed(futures):
            vt = futures[future]
            try:
                future.result()
                logger.info(f"[{comp_name}][{vt}] Thread finished ✓")
            except Exception:
                logger.error(f"[{comp_name}][{vt}] Thread raised an exception (other types continue)")

    elapsed = (datetime.now() - start_time).total_seconds()
    logger.info(f"[{comp_name}] Sync completed in {elapsed:.1f}s")

def sync_all_companies(
    companies:        list,
    tally:            TallyConnector,
    engine,
    to_date:          str,
    manual_from_date: str = None,
):
    if not companies:
        logger.warning("sync_all_companies: empty company list")
        return

    invalid_names = {'', 'N/A', 'NA', 'NONE'}
    valid = [c for c in companies if c.get('name', '').strip().upper() not in invalid_names]
    skipped = len(companies) - len(valid)
    logger.info(f"Syncing {len(valid)} companies (skipped {skipped} invalid entries)")

    for company in valid:
        sync_company(
            company          = company,
            tally            = tally,
            engine           = engine,
            to_date          = to_date,
            manual_from_date = manual_from_date,
        )